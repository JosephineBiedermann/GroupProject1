{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 - Data Scientist Job Market (US)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those who are actively looking for data scientist jobs in the U.S., the best news this month is the LinkedIn Workforce Report August 2018. According to the report, there is a shortage of 151,717 people with data science skills, with particularly acute shortages in New York City, San Francisco Bay Area and Los Angeles.\n",
    "\n",
    "To help job hunters (including me) to better understand the job market, I scraped Indeed website and collected information of 7,000 data scientist jobs around the U.S. on August 3rd. The information that I collected are: Company Name, Position Name, Location, Job Description, and Number of Reviews of the Company.\n",
    "\n",
    "Source: https://www.kaggle.com/sl6149/data-scientist-job-market-in-the-us?select=alldata.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Dos:\n",
    "1. Create a repo on GitHub - <span style=\"color:green\">done</span>\n",
    "2. Create a jupyter notebook - <span style=\"color:green\">done</span>\n",
    "3. What wrangling steps we want to do on each column - <span style=\"color:green\">done</span>\n",
    "<br>\n",
    "    3.1 Define the key words we want to extract from description - <span style=\"color:green\">done</span>\n",
    "    <br>\n",
    "    3.2 Find Regexs for it\n",
    "    <br>\n",
    "4. What insights we want to gather (e.g. company vs locations) - <span style=\"color:green\">done</span>\n",
    "<br>\n",
    "    4.1 How we want to present it (which plots to use) - <span style=\"color:green\">done</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. What wrangling steps we want to do on each column\n",
    "\n",
    "#### Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- standardize column headers\n",
    "- check null values (how many are there, etc)\n",
    "    - can we replace them\n",
    "    - can we drop them\n",
    "- standardize column 'positions'\n",
    "    - find unique values\n",
    "    - harmonize them\n",
    "- standardize column 'company'\n",
    "    - check for same description just wirtten differently/ typos\n",
    "    - correct them\n",
    "- standardize column 'location'\n",
    "    - split up into new columns (State, etc.)\n",
    "- extract words from column 'desrciption'\n",
    "    - use boolean columns with True or False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key words to look for in description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use re.findall()\n",
    "<br>\n",
    "<br>\n",
    "**We decided to focus on 3 Key word: languages, degrees and seniority level to not overwhelm the todos***\n",
    "\n",
    "**Languages:**\n",
    "<br>\n",
    "  - Python\n",
    "  - C\n",
    "  - C ++\n",
    "  - R\n",
    "  - Perl\n",
    "  - Java\n",
    "    <br>\n",
    "    \n",
    "**Degrees:**\n",
    "<br>\n",
    "  - Bachelor / BA /BS \n",
    "        * Computer Science, Economics, Data Science, \n",
    "  - Master /MA\n",
    "    <br>\n",
    "    \n",
    "**Seniotiry Level:**\n",
    "  - Junior\n",
    "  - Senior\n",
    "    <br>\n",
    "    \n",
    "**Tools:**\n",
    "<br>\n",
    "  - Tableau/QlikSense, PoerBI, Looker\n",
    "    <br>\n",
    "    \n",
    "**Skills:**\n",
    "<br>\n",
    "  - Big Data\n",
    "  - structured /un strcutured data\n",
    "  - discover pattern\n",
    "  - model / modeling\n",
    "  - advanced analystics\n",
    "  - 5+ years of Predictive Analytics\n",
    "  - Statistical Modeling\n",
    "  - Machine Learning\n",
    "    <br>\n",
    "\n",
    "    \n",
    "**Programms:**\n",
    "<br>\n",
    "  - Hadoop, Oracle, SQL\n",
    "    <br>\n",
    "    \n",
    "**Business Functions:**\n",
    "<br>\n",
    "  - Sales, Marketing, Supply Chain, Manufacturing \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RegEx to get those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What insights we want to gather (e.g. company vs locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights & presentation options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Giving overview of data:**\n",
    "<br>\n",
    "- job titels -> wordcloud (https://www.python-graph-gallery.com/wordcloud/)<br>\n",
    "<br>\n",
    "- most required skills -> sns.countplot \n",
    "<br>\n",
    "<br>\n",
    "- most required languages -> sns.countplot or treemap (https://www.python-graph-gallery.com/treemap/)\n",
    "<br>\n",
    "<br>\n",
    "- most required tools -> sns.countplot\n",
    "<br>\n",
    "<br>\n",
    "- ranking what is most important skills vs languages vs tools -> sns.countplot \n",
    "<br>\n",
    "<br>\n",
    "- locations -> bubble map (https://www.python-graph-gallery.com/bubble-map/)\n",
    "<br>\n",
    "<br>\n",
    "- companies -> donut plot (https://www.python-graph-gallery.com/donut-plot/)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**Showing relations between the columns:**\n",
    "<br>\n",
    "- all together (job titel, degree, company, location, languages, skills, tools) -> heatmap\n",
    "<br>\n",
    "<br>\n",
    "- degree vs job titel (degree vs company) -> -> scatterplot seaborn \n",
    "<br>\n",
    "<br>\n",
    "- location vs job titel (company vs location) -> scatterplot seaborn\n",
    "<br>\n",
    "<br>\n",
    "- tools vs job titel -> scatterplot seaborn\n",
    "<br>\n",
    "<br>\n",
    "- languages vs job titel -> scatterplot seaborn\n",
    "<br>\n",
    "<br>\n",
    "- skills vs job titel -> scatterplot seaborn\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/josephinebiedermann/Desktop/DABC2021/GitHub/ProjectsPhine/Week1/Data\n"
     ]
    }
   ],
   "source": [
    "cd Data #just going on directory down to get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31malldata.csv\u001b[m\u001b[m*     \u001b[31mfulltimeBOS.csv\u001b[m\u001b[m* \u001b[31mfulltimeMA.csv\u001b[m\u001b[m*  \u001b[31mfulltimeSD.csv\u001b[m\u001b[m*\r\n",
      "\u001b[31mfulltimeAL.csv\u001b[m\u001b[m*  \u001b[31mfulltimeCHI.csv\u001b[m\u001b[m* \u001b[31mfulltimeMV.csv\u001b[m\u001b[m*  \u001b[31mfulltimeSEA.csv\u001b[m\u001b[m*\r\n",
      "\u001b[31mfulltimeAT.csv\u001b[m\u001b[m*  \u001b[31mfulltimeDC.csv\u001b[m\u001b[m*  \u001b[31mfulltimeNY.csv\u001b[m\u001b[m*  \u001b[31mfulltimeSF.csv\u001b[m\u001b[m*\r\n",
      "\u001b[31mfulltimeBO.csv\u001b[m\u001b[m*  \u001b[31mfulltimeLA.csv\u001b[m\u001b[m*  \u001b[31mfulltimeRM.csv\u001b[m\u001b[m*  \u001b[31mfulltimeSU.csv\u001b[m\u001b[m*\r\n"
     ]
    }
   ],
   "source": [
    "ls #forgot how the file was called, so checking whats in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"alldata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>position</th>\n",
       "      <th>company</th>\n",
       "      <th>description</th>\n",
       "      <th>reviews</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Development Director</td>\n",
       "      <td>ALS TDI</td>\n",
       "      <td>Development Director\\nALS Therapy Development ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlanta, GA 30301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An Ostentatiously-Excitable Principal Research...</td>\n",
       "      <td>The Hexagon Lavish</td>\n",
       "      <td>Job Description\\n\\n\"The road that leads to acc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Xpert Staffing</td>\n",
       "      <td>Growing company located in the Atlanta, GA are...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Operation HOPE</td>\n",
       "      <td>DEPARTMENT: Program OperationsPOSITION LOCATIO...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Atlanta, GA 30303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assistant Professor -TT - Signal Processing &amp; ...</td>\n",
       "      <td>Emory University</td>\n",
       "      <td>DESCRIPTION\\nThe Emory University Department o...</td>\n",
       "      <td>550.0</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6959</th>\n",
       "      <td>Data Developer / Machine Learning Analyst</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>Are you data-driven? We at NetApp believe in t...</td>\n",
       "      <td>574.0</td>\n",
       "      <td>Sunnyvale, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6960</th>\n",
       "      <td>Scientist I</td>\n",
       "      <td>Pharmacyclics, an Abbvie Company</td>\n",
       "      <td>Pharmacyclics is committed to the development ...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Sunnyvale, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6961</th>\n",
       "      <td>Intern Scientist</td>\n",
       "      <td>Oath Inc</td>\n",
       "      <td>Oath, a subsidiary of Verizon, is a values-led...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Sunnyvale, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6962</th>\n",
       "      <td>Senior Data &amp; Applied Scientist</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>We are the Bing Core Relevance team responsibl...</td>\n",
       "      <td>4618.0</td>\n",
       "      <td>Sunnyvale, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6963</th>\n",
       "      <td>Principal Data Scientist, Deep Learning</td>\n",
       "      <td>Comcast</td>\n",
       "      <td>Comcast’s Technology &amp;amp; Product organizatio...</td>\n",
       "      <td>11610.0</td>\n",
       "      <td>Sunnyvale, CA 94089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6964 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               position  \\\n",
       "0                                  Development Director   \n",
       "1     An Ostentatiously-Excitable Principal Research...   \n",
       "2                                        Data Scientist   \n",
       "3                                          Data Analyst   \n",
       "4     Assistant Professor -TT - Signal Processing & ...   \n",
       "...                                                 ...   \n",
       "6959          Data Developer / Machine Learning Analyst   \n",
       "6960                                        Scientist I   \n",
       "6961                                   Intern Scientist   \n",
       "6962                    Senior Data & Applied Scientist   \n",
       "6963            Principal Data Scientist, Deep Learning   \n",
       "\n",
       "                               company  \\\n",
       "0                              ALS TDI   \n",
       "1                   The Hexagon Lavish   \n",
       "2                       Xpert Staffing   \n",
       "3                       Operation HOPE   \n",
       "4                     Emory University   \n",
       "...                                ...   \n",
       "6959                            NetApp   \n",
       "6960  Pharmacyclics, an Abbvie Company   \n",
       "6961                          Oath Inc   \n",
       "6962                         Microsoft   \n",
       "6963                           Comcast   \n",
       "\n",
       "                                            description  reviews  \\\n",
       "0     Development Director\\nALS Therapy Development ...      NaN   \n",
       "1     Job Description\\n\\n\"The road that leads to acc...      NaN   \n",
       "2     Growing company located in the Atlanta, GA are...      NaN   \n",
       "3     DEPARTMENT: Program OperationsPOSITION LOCATIO...     44.0   \n",
       "4     DESCRIPTION\\nThe Emory University Department o...    550.0   \n",
       "...                                                 ...      ...   \n",
       "6959  Are you data-driven? We at NetApp believe in t...    574.0   \n",
       "6960  Pharmacyclics is committed to the development ...     26.0   \n",
       "6961  Oath, a subsidiary of Verizon, is a values-led...      5.0   \n",
       "6962  We are the Bing Core Relevance team responsibl...   4618.0   \n",
       "6963  Comcast’s Technology &amp; Product organizatio...  11610.0   \n",
       "\n",
       "                 location  \n",
       "0      Atlanta, GA 30301   \n",
       "1             Atlanta, GA  \n",
       "2             Atlanta, GA  \n",
       "3      Atlanta, GA 30303   \n",
       "4             Atlanta, GA  \n",
       "...                   ...  \n",
       "6959        Sunnyvale, CA  \n",
       "6960        Sunnyvale, CA  \n",
       "6961        Sunnyvale, CA  \n",
       "6962        Sunnyvale, CA  \n",
       "6963  Sunnyvale, CA 94089  \n",
       "\n",
       "[6964 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data #having a first look at the data in the df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview/Shape Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6964, 5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "\n",
    "#we have 6965 rows and 5 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6964 entries, 0 to 6963\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   position     6953 non-null   object \n",
      " 1   company      6953 non-null   object \n",
      " 2   description  6953 non-null   object \n",
      " 3   reviews      5326 non-null   float64\n",
      " 4   location     6953 non-null   object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 272.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()\n",
    "\n",
    "#we have 4 columns that have datatype object, reviews data type is float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standardize column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['position', 'company', 'description', 'reviews', 'location'], dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns\n",
    "\n",
    "#column headers look already good, no need to change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check null values (how many are there, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6964 entries, 0 to 6963\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   position     6953 non-null   object \n",
      " 1   company      6953 non-null   object \n",
      " 2   description  6953 non-null   object \n",
      " 3   reviews      5326 non-null   float64\n",
      " 4   location     6953 non-null   object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 272.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6964 - 6953\n",
    "\n",
    "# it seems like in all object columns there are 11 NaN values each\n",
    "# i would assume this is the same 11 rows for all columns\n",
    "# this might indicate that we could drop those rows as they seem to be empty anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1638"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6964 - 5326\n",
    "\n",
    "# in reviews we have 1638 NaNs, which is  24% of the whole rows in the reviews column\n",
    "# i would suggest NOT to drop those rows, but to replace the NaNs with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1682"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum().sum() \n",
    "#there are in total 1682 NaN values over the whole df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "position         11\n",
       "company          11\n",
       "description      11\n",
       "reviews        1638\n",
       "location         11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "supplying multiple axes to axis is no longer supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-c8d347618a5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_clean1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'position'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'company'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'description'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'location'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'any'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata_clean1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdropna\u001b[0;34m(self, axis, how, thresh, subset, inplace)\u001b[0m\n\u001b[1;32m   4987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4988\u001b[0m             \u001b[0;31m# GH20987\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4989\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"supplying multiple axes to axis is no longer supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4991\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: supplying multiple axes to axis is no longer supported."
     ]
    }
   ],
   "source": [
    "data_clean1 = data.dropna(['position','company', 'description', 'location'], how = 'any')\n",
    "data_clean1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5326 entries, 3 to 6963\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   position     5326 non-null   object \n",
      " 1   company      5326 non-null   object \n",
      " 2   description  5326 non-null   object \n",
      " 3   reviews      5326 non-null   float64\n",
      " 4   location     5326 non-null   object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 249.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data_clean1 = data.dropna(subset = ['position'])\n",
    "data_clean1.info()\n",
    "\n",
    "# ??? how do i just drop the null values from columns 'position','company', 'description', 'location'??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5326 entries, 3 to 6963\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   position     5326 non-null   object \n",
      " 1   company      5326 non-null   object \n",
      " 2   description  5326 non-null   object \n",
      " 3   reviews      5326 non-null   float64\n",
      " 4   location     5326 non-null   object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 249.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data_clean2 = data.dropna()\n",
    "data_clean2.info()\n",
    "\n",
    "#here we have also dropped the NaN values from reviews, thats what i did not wanted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standardize column 'positions'\n",
    "- find unique values\n",
    "- harmonize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new column called 'positions_clean'\n",
    "# take davis list and extract the clean names from positions to 'positions_clean'\n",
    "# do value count per position\n",
    "# take top 3 and take this for correlcations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5326"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['position'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Data Analyst',\n",
       "       'Assistant Professor -TT - Signal Processing & Machine Learning',\n",
       "       'Manager of Data Engineering', ...,\n",
       "       'Data Developer / Machine Learning Analyst', 'Intern Scientist',\n",
       "       'Principal Data Scientist, Deep Learning'], dtype=object)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['position'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data Scientist                                          204\n",
       "Senior Data Scientist                                    53\n",
       "Research Analyst                                         44\n",
       "Data Engineer                                            39\n",
       "Machine Learning Engineer                                26\n",
       "                                                       ... \n",
       "WRF-Hydro/National Water Model Software Engineer III      1\n",
       "Experience Management Scientist, Employee Experience      1\n",
       "Scientist II, PK/PD and PBPK Modeling                     1\n",
       "Director                                                  1\n",
       "Data Science - Data Scientist - New York                  1\n",
       "Name: position, Length: 4221, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['position'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "davis list:\n",
    "\n",
    "research scientist\n",
    "data scientist\n",
    "data analyst\n",
    "data engineer\n",
    "machine learning engineer\n",
    "business analyst\n",
    "research analyst\n",
    "web analyst\n",
    "finance analyst\n",
    "research associate\n",
    "associate scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = ['research scientist', 'data scientist', 'data analyst', 'data engineer',\n",
    "'business analyst',\n",
    "'research analyst',\n",
    "'web analyst',\n",
    "'finance analyst',\n",
    "'research associate',\n",
    "'associate scientist', 'data analyst', 'engineer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>position</th>\n",
       "      <th>company</th>\n",
       "      <th>description</th>\n",
       "      <th>reviews</th>\n",
       "      <th>location</th>\n",
       "      <th>positions_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Operation HOPE</td>\n",
       "      <td>DEPARTMENT: Program OperationsPOSITION LOCATIO...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Atlanta, GA 30303</td>\n",
       "      <td>data analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assistant Professor -TT - Signal Processing &amp; ...</td>\n",
       "      <td>Emory University</td>\n",
       "      <td>DESCRIPTION\\nThe Emory University Department o...</td>\n",
       "      <td>550.0</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Manager of Data Engineering</td>\n",
       "      <td>McKinsey &amp; Company</td>\n",
       "      <td>Qualifications\\nBachelor’s degree in Computer ...</td>\n",
       "      <td>385.0</td>\n",
       "      <td>Atlanta, GA 30318</td>\n",
       "      <td>data engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Product Specialist - Periscope, New Ventures</td>\n",
       "      <td>McKinsey &amp; Company</td>\n",
       "      <td>Qualifications\\nBachelor’s degree\\n5-7 years o...</td>\n",
       "      <td>385.0</td>\n",
       "      <td>Atlanta, GA 30318</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Junior to Mid-level Engineer, Geologist or Env...</td>\n",
       "      <td>Wood</td>\n",
       "      <td>Overview / Responsibilities\\nWood Environment ...</td>\n",
       "      <td>899.0</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>engineer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            position             company  \\\n",
       "3                                       Data Analyst      Operation HOPE   \n",
       "4  Assistant Professor -TT - Signal Processing & ...    Emory University   \n",
       "5                        Manager of Data Engineering  McKinsey & Company   \n",
       "6       Product Specialist - Periscope, New Ventures  McKinsey & Company   \n",
       "7  Junior to Mid-level Engineer, Geologist or Env...                Wood   \n",
       "\n",
       "                                         description  reviews  \\\n",
       "3  DEPARTMENT: Program OperationsPOSITION LOCATIO...     44.0   \n",
       "4  DESCRIPTION\\nThe Emory University Department o...    550.0   \n",
       "5  Qualifications\\nBachelor’s degree in Computer ...    385.0   \n",
       "6  Qualifications\\nBachelor’s degree\\n5-7 years o...    385.0   \n",
       "7  Overview / Responsibilities\\nWood Environment ...    899.0   \n",
       "\n",
       "             location positions_clean  \n",
       "3  Atlanta, GA 30303     data analyst  \n",
       "4         Atlanta, GA             NaN  \n",
       "5  Atlanta, GA 30318    data engineer  \n",
       "6  Atlanta, GA 30318              NaN  \n",
       "7         Atlanta, GA        engineer  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['positions_clean'] = data['position'].str.extract('({})'.format('|'.join(positions)), \n",
    "                        flags=re.IGNORECASE, expand=False).str.lower()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data scientist         872\n",
       "engineer               857\n",
       "research analyst       243\n",
       "research scientist     205\n",
       "data engineer          128\n",
       "data analyst           102\n",
       "associate scientist     72\n",
       "research associate      63\n",
       "business analyst        23\n",
       "finance analyst         15\n",
       "web analyst              1\n",
       "Name: positions_clean, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['positions_clean'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2581"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['positions_clean'].value_counts().sum()\n",
    "\n",
    "# even though we are missing hlaf of the entires, we have the positons that we are acutally interesetd in \n",
    "# we will disregard the entries for e.g. web devloper or marketing analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['data analyst', nan, 'data engineer', 'engineer', 'data scientist',\n",
       "       'research scientist', 'research analyst', 'associate scientist',\n",
       "       'finance analyst', 'research associate', 'business analyst',\n",
       "       'web analyst'], dtype=object)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['positions_clean'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standardize column 'company'\n",
    "- check for same description just wirtten differently/ typos\n",
    "- correct them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Operation HOPE', 'Emory University', 'McKinsey & Company', ...,\n",
       "       'ALTA DEVICES INC', 'Magic Leap, Inc.', 'Nexient'], dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['company'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Amazon.com                         357\n",
       "Ball Aerospace                     187\n",
       "Microsoft                          137\n",
       "Google                             134\n",
       "NYU Langone Health                  76\n",
       "                                  ... \n",
       "Verra Mobility                       1\n",
       "Liberty Healthcare Corporation       1\n",
       "Grenzebach Glier and Associates      1\n",
       "Group One Trading                    1\n",
       "Poshmark                             1\n",
       "Name: company, Length: 1302, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['company'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Growing company located in the Atlanta, GA area is currently looking to add a Data Scientist to their team. The Data Scientist will analyze business level data to produce actionable insights utilizing analytics tools and languages, etc. R, Python and/or C++: The Data Scientist will serve as the organization’s leader, helping to grow their data science initiative from a green state. The Data Scientist will also be responsible for advancement of analytical projects from inception to delivery and beyond.\\nRESPONSIBLITIES;\\n 1. Leverage Big Data to discover patterns and solve strategic and tactical business problems using massive structured and unstructured data sets across multiple environments\\n 2. Develop analytical capabilities (modeling and processes) that drive better outcomes for both customers and the company\\n 3. Drive the collection, cleansing, processing and analysis of new and existing data sources.\\n 4. Research industry topics impacting opportunities relevant for data analysis projects\\n 5. Execute complex analyses to aid in reporting and interpretation of analytical findings to build a comprehensive solution.\\n 6. Demonstrates good judgment and analytical skills to conduct option analysis and present recommendations\\n 7. Support and resolve issues related to analyses or deliverable in production\\n 8. Works with internal and external clients to understand, clarify, and analyze requirements to understand the business, and potential, impactful solutions\\n 9. Mapping of processes to understand opportunities for advanced analytics and product enhancement\\n\\n\\nRequirements:\\n5. 1. BA/BS Degree in Business Analysis, Computer Science, Economics, Data Science. Masters degree preferred\\n 2. 5+ years of Predictive Analytics, Statistical Modeling, Machine Learning a plus\\n 3. Expect level understanding of analytics tools and language (R, Python, or C++ etc.)\\n 4. Experienced in Business Analysis, requirement definition\\n 5. Proven and recent experience working with Sales, Marketing, Supply Chain, and/or Manufacturing Data\\n 6. Able to navigate and access structured and unstructured data environments (i.e. Hadoop, Oracle, SQL etc)\\n 7. Experience utilizing internal and external data sources to identify otherwise hidden industry trends to impact product development\\n 8. Exposure to visualization tools, Tableau/QlikSense\\n 9. Must be solution-oriented and focused on innovation.\\n 10. Familiar with scripting language: e.g. Perl, Python or a programming language: e.g. Java\\n \\n\\nTo express interest in this position, please Email Resume in MS-Word or .pdf format and attach cover letter with Salary requirements and contact information. Please be sure to reference Job #2093.\\n NO SPONSORSHIP AVAILABLE!\\n\\n\\nLocation: Atlanta, GA\\n\\nType: Permanent\\n\\nSalary: $$,$$$ / DOE'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['description'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Development Director',\n",
       "       'An Ostentatiously-Excitable Principal Research Assistant to Chief Scientist',\n",
       "       'Data Scientist', ..., 'Data Developer / Machine Learning Analyst',\n",
       "       'Intern Scientist', 'Principal Data Scientist, Deep Learning'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['position'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data Scientist                                             351\n",
       "Senior Data Scientist                                       96\n",
       "Research Analyst                                            64\n",
       "Data Engineer                                               60\n",
       "Machine Learning Engineer                                   56\n",
       "                                                          ... \n",
       "Software Engineer - Android                                  1\n",
       "Data Engineer, Amazon Prime                                  1\n",
       "Sr. Quantitative Analyst                                     1\n",
       "Program Manager, Mixed Reality Content                       1\n",
       "Postdoctoral Scientist - Optical Physics , Biophotonics      1\n",
       "Name: position, Length: 5242, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['position'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6964"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (0) does not match length of index (6964)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-2c7ceaeb863b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdegrees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'BA|Bachelor'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'degrees'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIGNORECASE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3038\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3039\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3040\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3114\u001b[0m         \"\"\"\n\u001b[1;32m   3115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3116\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3117\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3764\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3765\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3766\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    745\u001b[0m     \"\"\"\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    748\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (0) does not match length of index (6964)"
     ]
    }
   ],
   "source": [
    "degrees = 'BA|Bachelor'\n",
    "data['degrees'] = re.findall(degrees, str(data['description']), flags=re.IGNORECASE)\n",
    "\n",
    "# if BA or Bachelor is in the cell, I want to extract it into a new column called 'degrees'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
